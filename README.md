# ğŸš— BMW PoC â€” Offline RAG + Generative AI Demo

### A Dual-Pipeline AI Sandbox built for Automotive Knowledge Intelligence and Synthetic Data Generation

---

## ğŸŒ Overview

This Proof of Concept (PoC) demonstrates a **fully offline, end-to-end AI stack** that combines:

1. **Retrieval-Augmented Generation (RAG)** â€” for intelligent document understanding and question answering over internal PDFs.  
2. **Generative Adversarial Networks (DCGAN)** â€” for local image synthesis and experimentation in data generation.

All components run **locally on CPU/GPU**, using open-source models and frameworks (PyTorch, FAISS, BM25, llama.cpp).  
No internet or API dependency â€” ideal for secure, on-premises use cases such as **BMWâ€™s automotive R&D data environments**.

---

## ğŸ§© System Architecture

### **1. Retrieval-Augmented Generation (RAG)**

#### **Goal**
Enable intelligent, citation-grounded answers from internal PDFs using local models.

#### **Pipeline Flow**

```
PDFs â†’ Text Extraction â†’ Chunking â†’ Embedding
       â†“
   FAISS (dense) + BM25 (sparse)
       â†“
 Hybrid Fusion + Cross-Encoder Reranking
       â†“
 TinyLlama GGUF â†’ Grounded Answer Generation
```

#### **Modules**
| Stage | File | Description |
|--------|------|-------------|
| **Ingest** | `rag/ingest.py` | Extracts text from PDFs, chunks text, builds FAISS and BM25 indexes. |
| **Retrieve** | `rag/retrieve.py` | Combines dense (semantic) and sparse (keyword) retrieval results. |
| **Rerank** | `rag/rerank.py` | Cross-encoder model (`ms-marco-MiniLM-L6-v2`) ranks final passages. |
| **Generate** | `rag/generate.py` | TinyLlama GGUF model (via llama.cpp) produces contextual answers. |
| **Guardrails** | `rag/guardrails.py` | Cleans and filters sensitive or irrelevant responses. |
| **Eval** | `rag/eval.py` | Reports latency metrics and pipeline statistics. |

#### **Retrieval Config (YAML)**

```yaml
retrieval:
  k_dense: 50
  k_bm25: 50
  k_fused: 40
  dense_weight: 0.65
  bm25_weight: 0.35

rerank:
  top_k: 6
```

**Why this matters:**  
- FAISS captures semantic similarity.  
- BM25 ensures keyword coverage.  
- Cross-Encoder refines relevance.  
- Fusion balances precision and recall â€” a practical hybrid used in enterprise RAG systems.

---

### **2. Generative Component (DCGAN)**

#### **Goal**
Showcase a fast, local generative model that can create synthetic grayscale images â€” useful for concept demos or automotive data simulation.

#### **Architecture**
| Network | File | Description |
|----------|------|-------------|
| **Generator** | `generative/gan_dcgan.py` | Converts random noise (latent vector) into 32Ã—32 images via transposed convolutions. |
| **Discriminator** | `generative/gan_dcgan.py` | Classifies images as real or fake via convolutional layers and global pooling. |

#### **Training Workflow**
1. Dataset â†’ Fashion-MNIST or Custom grayscale icons.  
2. Alternate between:
   - **D-Step:** Train discriminator on real + fake samples.
   - **G-Step:** Train generator to fool the discriminator.
3. Save:
   - Checkpoint â†’ `data/generated/dcgan/dcgan_latest.pt`
   - Preview grid â†’ `data/generated/dcgan/preview.png`

**Core Hyperparameters**
```python
epochs = 2
lr = 2e-4
nz = 32
img_size = 32
batch_size = 128
```

---

## ğŸ–¥ï¸ Streamlit UI

The Streamlit dashboard acts as the control center â€” unifying the RAG and GAN pipelines.

### **Sidebar â€” Model & Inference Configuration**

| Parameter | Description | Range / Default |
|------------|-------------|----------------|
| **k (fused candidates)** | No. of top chunks retained after fusion | 20â€“60 (default: 40) |
| **Rerank top_k** | Chunks passed to cross-encoder | 4â€“10 (default: 6) |
| **Max new tokens** | LLM output length limit | 128â€“512 |
| **Temperature** | Sampling randomness | 0.2â€“0.7 |
| **Top-p** | Nucleus sampling threshold | 0.8â€“0.95 |

---

### **Tabs Overview**

#### ğŸ“˜ **Ingest PDFs**
Upload files â†’ click **Build / Rebuild Indexes**.  
Creates FAISS + BM25 indexes and saves metadata in JSONL.

#### ğŸ’¬ **Search & Answer**
Ask questions â†’ retrieves, reranks, and generates grounded answers from the ingested PDFs.  
Citations like `[id p2]` show where the answer came from.

#### ğŸ“ˆ **Metrics**
Displays latency (p50/p95) for retrieval and reranking.  
Future extension for Recall@k, nDCG, and Faithfulness metrics.

#### ğŸ“‹ **Inspect Index**
Preview ~50 text chunks from the FAISS/BM25 indexes for data verification.

#### ğŸ§¬ **Generative (DCGAN)**
Train or sample from a local GAN.
- **Quick Demo:** Fashion-MNIST (auto-downloaded)
- **Fine-Tune Mode:** Uses images from `data/custom_images/`

Buttons:
- **Train** â†’ Trains DCGAN (logs to console)
- **Generate Now** â†’ Produces image grid + downloadable ZIP

---

## ğŸ§± Folder Structure

```
poc-bmw/
â”‚
â”œâ”€â”€ app/                     # Streamlit entry point and dependency manager
â”œâ”€â”€ rag/                     # Ingestion, retrieval, rerank, generation, guardrails
â”œâ”€â”€ generative/              # DCGAN and dataset generator scripts
â”œâ”€â”€ ui/                      # Streamlit UI components and layout
â”œâ”€â”€ configs/                 # YAML configs (paths, retrieval, generation)
â”œâ”€â”€ models/                  # GGUF + transformer models
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                 # Input PDFs
â”‚   â”œâ”€â”€ index/               # FAISS / BM25 indexes
â”‚   â””â”€â”€ generated/dcgan/     # GAN checkpoints and previews
â””â”€â”€ README.md
```

---

## âš™ï¸ Configuration (`configs/default.yaml`)

```yaml
paths:
  raw_dir: "data/raw"
  index_dir: "data/index"
  gguf_model: "models/gguf/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf"

chunking:
  size: 600
  overlap: 80

retrieval:
  k_dense: 50
  k_bm25: 50
  k_fused: 40
  dense_weight: 0.65
  bm25_weight: 0.35

rerank:
  top_k: 6

generation:
  max_new_tokens: 256
  temperature: 0.4
  top_p: 0.9
```

---

## ğŸ§¾ Key Artifacts

| Artifact | Description | Path |
|-----------|--------------|------|
| **FAISS Index** | Dense vector index | `data/index/text.faiss` |
| **BM25 Index** | Sparse keyword index | `data/index/bm25.pkl` |
| **Chunk Map** | JSONL mapping of text chunks | `data/index/text_ids.jsonl` |
| **DCGAN Checkpoint** | Latest model weights | `data/generated/dcgan/dcgan_latest.pt` |
| **Preview Image** | DCGAN grid snapshot | `data/generated/dcgan/preview.png` |

---

## ğŸš€ How to Run

```bash
# 1. Install dependencies
pip install -r requirements.txt

# 2. Launch the Streamlit app
streamlit run ui/streamlit_app.py

# 3. Access UI at
http://localhost:8501
```

**Steps:**
1. In â€œIngest PDFsâ€ â†’ upload files â†’ Build Index.  
2. In â€œSearch & Answerâ€ â†’ type queries â†’ view contextual responses.  
3. In â€œGenerativeâ€ â†’ train or generate images via DCGAN.

---

## ğŸ§  Technology Stack

| Component | Technology |
|------------|-------------|
| **UI Layer** | Streamlit |
| **Vector Store** | FAISS (dense) + BM25 (sparse) |
| **Embedding Model** | SentenceTransformer â€“ all-MiniLM-L6-v2 |
| **Reranker** | Cross-Encoder â€“ ms-marco-MiniLM-L6-v2 |
| **LLM** | TinyLlama (GGUF, via llama.cpp) |
| **Framework** | PyTorch |
| **Generative Model** | DCGAN |
